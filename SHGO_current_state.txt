=== SHGO.jl - Aktueller Code-Stand === 
Generiert am 28.12.2025 um 13:54:36,62 
 
------------------------Dateitrennzeichen--------------------------------------------- 
 
"Datei: C:\Users\uweal\SHGO.jl\CLUSTERINGDEBUG.jl" 
```julia 
using Pkg
Pkg.activate(".")

using SHGO
using NonlinearOptimizationTestFunctions
using Printf

println("="^80)
println("CLUSTERING DEBUG - Six-Hump-Camelback")
println("="^80)

tf = fixed(TEST_FUNCTIONS["sixhumpcamelback"]; n=2)

# Test mit moderater Aufl√∂sung
n_div = 12
println("\n--- Analyse mit n_div = $n_div, OHNE Gradient-Pruning ---\n")

# F√ºhre Analyse durch
res = analyze(tf; n_div = n_div, verbose = true, use_gradient_pruning = false)

println("\n" * "="^80)
println("ERGEBNISSE")
println("="^80)
@printf "Gefundene Basins:    %d\n" res.num_basins
@printf "Lokale Minima:       %d\n" length(res.local_minima)

if !isempty(res.local_minima)
    println("\nGefundene Minima (nach Objective sortiert):")
    sorted = sort(res.local_minima, by = m -> m.objective)
    for (i, m) in enumerate(sorted)
        @printf "  %2d. f = %8.4f  @ (%.4f, %.4f)\n" i m.objective m.u[1] m.u[2]
    end
    
    # Pr√ºfe Unique-Werte (vielleicht Duplikate?)
    unique_objectives = unique([m.objective for m in res.local_minima])
    @printf "\nAnzahl UNIQUE Objective-Werte: %d\n" length(unique_objectives)
    
    if length(unique_objectives) < length(res.local_minima)
        println("‚ö†Ô∏è  WARNUNG: Es gibt Duplikate! Clustering findet mehrfach dasselbe Minimum.")
    end
end

println("\n" * "="^80)
println("DIAGNOSE")
println("="^80)
println("Erwartung:  6 verschiedene Minima")
println("Realit√§t:   Siehe oben")
println("\nM√∂gliche Probleme:")
println("  1. Gradient-Pruning wirft zu viele Simplizes weg")
println("  2. Clustering verbindet alles zu einem Basin")
println("  3. Grid zu grob ‚Üí lokale Minima nicht erfasst")
println("  4. Lokale Optimierung konvergiert mehrfach zum selben Punkt")
println("="^80)``` 
 
------------------------Dateitrennzeichen--------------------------------------------- 
 
"Datei: C:\Users\uweal\SHGO.jl\diagnose_sixhump.jl" 
```julia 
# diagnose_sixhump.jl
# Detaillierte Diagnose der Six-Hump-Camelback Probleme

using Pkg
Pkg.activate(".")

using SHGO
using NonlinearOptimizationTestFunctions
using Printf
using Statistics

println("="^80)
println("SIX-HUMP-CAMELBACK DIAGNOSE")
println("="^80)

tf = fixed(TEST_FUNCTIONS["sixhumpcamelback"]; n=2)

# Bekannte Minima aus der Literatur
known_minima = [
    ([-0.0898, 0.7126], -1.0316),
    ([0.0898, -0.7126], -1.0316),
    ([-1.7036, 0.7961], -0.2155),
    ([1.7036, -0.7961], -0.2155),
    ([-1.6071, -0.5687], 2.1040),
    ([1.6071, 0.5687], 2.1040)
]

println("\nBekannte Minima:")
for (i, (pos, val)) in enumerate(known_minima)
    @printf "  %d. f(%.4f, %.4f) = %.4f\n" i pos[1] pos[2] val
end

println("\n" * "="^80)
println("TEST 1: Verschiedene Grid-Aufl√∂sungen (OHNE Refinement) - FIXED VERSION")
println("="^80)

for n_div in [5, 8, 10, 12, 15,20,30]
    println("\n--- n_div = $n_div ---")
    
    res = analyze(tf; 
        n_div = n_div,
        verbose = false,
        use_gradient_pruning = false,
        refinement_levels = 0  # Erstmal ohne
    )
    
    @printf "Simplizes insgesamt: ~%d (theoretisch: %d Zellen * 2! = %d)\n" (n_div^2 * 2) (n_div^2) (n_div^2 * 2)
    @printf "Gefundene Basins:    %d\n" res.num_basins
    @printf "Lokale Minima:       %d\n" length(res.local_minima)
    
    if !isempty(res.local_minima)
        println("\nGefundene Minima (sortiert):")
        sorted = sort(res.local_minima, by = m -> m.objective)
        for (i, m) in enumerate(sorted)
            @printf "  %d. f = %8.4f  @ (%.4f, %.4f)\n" i m.objective m.u[1] m.u[2]
        end
        
        # Pruefe Abstand zu bekannten Minima
        global_found = abs(sorted[1].objective + 1.0316) < 0.01
        println("\nGlobales Minimum gefunden: $(global_found ? "ja" : "nein")")
    end
end

println("\n" * "="^80)
println("TEST 2: Mit Gradient-Pruning")
println("="^80)

for use_pruning in [false, true]
    println("\n--- Gradient-Pruning: $use_pruning ---")
    
    res = analyze(tf; 
        n_div = 12,
        verbose = false,
        use_gradient_pruning = use_pruning,
        refinement_levels = 0
    )
    
    @printf "Gefundene Basins:  %d\n" res.num_basins
    @printf "Lokale Minima:     %d\n" length(res.local_minima)
    
    if !isempty(res.local_minima)
        best = minimum(m.objective for m in res.local_minima)
        @printf "Bestes Minimum:    %.6f\n" best
    end
end

println("\n" * "="^80)
println("TEST 3: Mit Refinement (kann langsam sein!)")
println("="^80)

for ref_level in [0, 1, 2]
    println("\n--- Refinement Level: $ref_level ---")
    
    res = analyze(tf; 
        n_div = 8,  # Kleiner, weil Refinement multipliziert
        verbose = false,
        use_gradient_pruning = false,
        refinement_levels = ref_level
    )
    
    @printf "Gefundene Basins:  %d\n" res.num_basins
    @printf "Lokale Minima:     %d\n" length(res.local_minima)
    
    if !isempty(res.local_minima)
        best = minimum(m.objective for m in res.local_minima)
        worst = maximum(m.objective for m in res.local_minima)
        @printf "Range:             %.4f bis %.4f\n" best worst
    end
end

println("\n" * "="^80)
println("TEST 4: Clustering-Detail-Analyse")
println("="^80)

# Manuell ein paar Simplizes erzeugen und Clustering testen
println("\nGeneriere Simplizes f√ºr n_div=10...")
res = analyze(tf; n_div=10, verbose=true, refinement_levels=0)

println("\n" * "="^80)
println("ZUSAMMENFASSUNG")
println("="^80)
println("Erwartung:  6 Basins (aus Literatur)")
println("Realit√§t:   Siehe oben - vermutlich deutlich weniger")
println("\nM√∂gliche Ursachen:")
println("  1. share_face() zu restriktiv/zu permissiv")
println("  2. Value-based Pruning zu aggressiv")
println("  3. Lokale Optimierung konvergiert nicht richtig")
println("  4. Grid zu grob f√ºr kleine Basins")
println("="^80)``` 
 
------------------------Dateitrennzeichen--------------------------------------------- 
 
"Datei: C:\Users\uweal\SHGO.jl\maintain.jl" 
```julia 
# File: maintain.jl
using Dates

function ultra_safe_maintenance(root_dir = pwd())
    timestamp = Dates.format(now(), "yyyymmdd_HHMMSS")
    log_file = joinpath(root_dir, "maintenance_$timestamp.log")
    
    open(log_file, "w") do log
        write(log, "Maintenance Start: $(now())\n" * "-"^40 * "\n")
        
        for (root, dirs, files) in walkdir(root_dir)
            # Versteckte Ordner wie .git ignorieren
            if occursin(".git", root) continue end
            
            for file in files
                if endswith(file, ".jl") && file != "maintenance_script.jl"
                    full_path = joinpath(root, file)
                    rel_path = relpath(full_path, root_dir)
                    
                    try
                        process_file_ultra_safe(full_path, rel_path, timestamp, log)
                    catch e
                        write(log, "ERROR bei $rel_path: $e\n")
                    end
                end
            end
        end
    end
    println("Abgeschlossen. Details findest du in: $log_file")
end

function process_file_ultra_safe(full_path, rel_path, ts, log_io)
    lines = readlines(full_path, keep=true)
    orig_count = length(lines)
    modified = false
    
    header = "# File: $rel_path\n"
    footer = "# End: $rel_path\n"

    # Header-Check (erste 5 Zeilen)
    if !any(occursin("# File: $rel_path", l) for l in lines[1:min(5, end)])
        insert!(lines, 1, header)
        modified = true
    end

    # Footer-Check (letzte 5 Zeilen)
    if !any(occursin("# End: $rel_path", l) for l in lines[max(1, end-4):end])
        if !isempty(lines) && !endswith(lines[end], "\n")
            lines[end] *= "\n"
        end
        push!(lines, footer)
        modified = true
    end

    if modified
        backup_path = full_path * ".$ts.bak"
        
        # 1. Backup schreiben
        cp(full_path, backup_path, force=false)
        
        if isfile(backup_path)
            # 2. Original schreiben
            open(full_path, "w") do f
                foreach(l -> write(f, l), lines)
            end
            
            # 3. Verifizieren
            new_count = length(readlines(full_path))
            if new_count >= orig_count
                write(log_io, "SUCCESS: $rel_path (Backup: $(basename(backup_path)))\n")
                println("‚úì $rel_path")
            else
                write(log_io, "WARNING: $rel_path k√∂nnte korrupt sein (Zeilen geschrumpft!)\n")
            end
        end
    else
        write(log_io, "SKIP: $rel_path (Bereits aktuell)\n")
    end
end

ultra_safe_maintenance()
# End: maintain.jl
``` 
 
------------------------Dateitrennzeichen--------------------------------------------- 
 
"Datei: C:\Users\uweal\SHGO.jl\run_analysis.jl" 
```julia 
# run_analysis.jl
# Starte mit: julia --project=. run_analysis.jl

using Pkg
Pkg.activate(".")

using SHGO
using NonlinearOptimizationTestFunctions
using Printf

println("=== SHGO Analyse - Six-Hump-Camelback (n=2) ===\n")

# Funktion laden
tf = fixed(TEST_FUNCTIONS["sixhumpcamelback"]; n=2)

# Parameter ‚Äì du kannst hier rumspielen
n_div              = 15       # 8‚Äì15 ist ein guter Bereich (mehr ‚Üí mehr Simplizes, langsamer)
use_grad_pruning   = false    # false = mehr Kandidaten, true = sehr aggressiv
verbose            = true
show_minima_detail = true     # Zeigt jedes gefundene lokale Minimum

println("Parameter:")
@printf "  Funktion:            %s\n" name(tf)
@printf "  Divisionen pro Achse: %d\n" n_div
@printf "  Gradient-Pruning:    %s\n" (use_grad_pruning ? "aktiviert" : "deaktiviert")
println("")

# Analyse starten
res = analyze(tf; 
    n_div = n_div,
    verbose = verbose,
    use_gradient_pruning = use_grad_pruning
)

# Ergebnis ausgeben
println("\n=== Ergebnis-Zusammenfassung ===")
@printf "Gefundene Basins:      %d\n" res.num_basins
@printf "Anzahl lokaler Minima: %d\n" length(res.local_minima)

if !isnothing(res.global_minimum)
    @printf "\nGlobales Minimum gefunden: f = %.6f\n" res.global_minimum.objective
    @printf "  Position: %.6f, %.6f\n" res.global_minimum.u[1] res.global_minimum.u[2]
else
    println("\nKein globales Minimum gefunden (noch zu wenige Kandidaten?)")
end

if show_minima_detail && !isempty(res.local_minima)
    println("\nGefundene lokale Minima (sortiert nach Objective):")
    sorted_minima = sort(res.local_minima, by = m -> m.objective)
    for (i, m) in enumerate(sorted_minima)
        @printf "  %2d.  f = %10.6f   @  (%.6f, %.6f)\n" i m.objective m.u[1] m.u[2]
    end
else
    println("\nKeine lokalen Minima gefunden ‚Äì evtl. mehr Divisionen oder weniger Pruning probieren?")
end

println("\nFertig. Viel Erfolg beim Feintuning! ü¶Ö")``` 
 
------------------------Dateitrennzeichen--------------------------------------------- 
 
"Datei: C:\Users\uweal\SHGO.jl\Project.toml" 
```julia 
name = "SHGO"
uuid = "0ee0e29c-01bb-55d7-8e26-92326ec34c1a"

[deps]
Combinatorics = "861a8166-3701-5b0c-9a16-15d98fcdc6aa"
DataStructures = "864edb3b-99cc-5e75-8d2d-829cb0a9cfe8"
Graphs = "86223c79-3864-5bf0-83f7-82e725a168b6"
LazySets = "b4f0291d-fe17-52bc-9479-3d1a343d9043"
LinearAlgebra = "37e2e46d-f89d-539d-b4ee-838fcccc9c8e"
NonlinearOptimizationTestFunctions = "3180b13f-e8d1-40aa-806b-3e6ce7522c6b"
Optimization = "7f7a1694-90dd-40f0-9382-eb1efda571ba"
OptimizationOptimJL = "36348300-93cb-4f02-beb5-3c3902f8871e"
Printf = "de0858da-6303-5e67-8744-51eddeeeb8d7"
SciMLBase = "0bca4576-84f4-4d90-8ffe-ffa030f20462"
StaticArrays = "90137ffa-7385-5640-81b9-e52037218182"
Statistics = "10745b16-79ce-11e8-11f9-7d13ad32a3b2"

[compat]
Combinatorics = "1.1.0"
DataStructures = "0.19.3"
``` 
 
------------------------Dateitrennzeichen--------------------------------------------- 
 
"Datei: C:\Users\uweal\SHGO.jl\README.md" 
```julia 

# SHGO.jl

**Stochastic Homology Global Optimization in Julia**

SHGO.jl ist nicht nur ein globaler Optimierer, sondern ein Instrument zur **Strukturanalyse von Optimierungslandschaften**. Es basiert auf der Idee, die topologische Information einer Zielfunktion zu nutzen, um alle lokalen Minima effizient zu finden und das globale Minimum zu garantieren.

---

## ‚ö†Ô∏è Der "Heureka-Moment": Korrektur der Basin-Theorie

In der fr√ºhen Entwicklung gab es einen fundamentalen logischen Fehler beim Clustering. Diese Erkenntnis ist der Kern der aktuellen Architektur:

### Das Problem: Premature Clustering

Fr√ºher wurde versucht, **aktive Simplizes** (Simplizes, in denen ein Minimum vermutet wird) zu gruppieren, *bevor* die lokale Optimierung stattfand.

* **Fehler:** "Multiplikative Barrieren". Zwei Simplizes k√∂nnen topologisch benachbart sein, aber zu zwei v√∂llig verschiedenen Minima f√ºhren.
* **Folge:** Basins wurden "verschmolzen", bevor sie existierten. Die Anzahl der gefundenen Minima war instabil.

### Die L√∂sung: Der SHGO-Flow (Korrekt)

1. **Sampling:** Den Raum in ein Gitter aus Simplizes unterteilen.
2. **Topologische Filterung:** Identifikation "aktiver" Simplizes (Kandidatenregionen).
3. **Lokale Optimierung:** *Jeder* aktive Simplex startet eine lokale Suche.
4. **Deduplizierung (Echtes Clustering):** Erst die *Resultate* der Optimierung werden anhand ihrer Distanz im Phasenraum gruppiert.

---

## üìò Terminologie & Taxonomie

Um Missverst√§ndnisse zu vermeiden (insbesondere im Vergleich zur SciPy-Implementierung), nutzt SHGO.jl folgende Definitionen:

| Begriff | Definition | Rolle im Algorithmus |
| --- | --- | --- |
| **Simplex** | Kleinste geometrische Einheit des Gitters. | Datenspeicher (Werte/Gradienten). |
| **Star-Domain** | Die Nachbarschaft um einen Vertex. | Basis f√ºr die Homologie-Analyse. |
| **Kandidaten-Region** | Zusammenh√§ngende Menge aktiver Simplizes. | Ein "topologisches Feature" der Landschaft. |
| **Attraction Basin** | Menge aller Punkte, die zum selben Minimum konvergieren. | **Wird erst nach Schritt 4 (Deduplizierung) gez√§hlt.** |

---

## üõ† Architektur & Design-Prinzipien

### 1. Separation of Concerns

* **TopicalManager:** Verwaltet die Geometrie und Topologie (Vertices, IDs, Simplex-Beziehungen).
* **Solver-Abstraktion:** Die lokale Optimierung ist entkoppelt.
* **Analyse-Layer:** Liefert ein "Profil" der Landschaft, nicht nur eine Zahl.

### 2. Eager vs. Lazy Evaluation

Im Gegensatz zu reinen Optimierern (die "Lazy" arbeiten, um Rechenzeit zu sparen), verfolgt SHGO.jl oft einen **Eager-Ansatz**:

* **Ziel:** Vollst√§ndige Abdeckung der Landschaft.
* **Vorteil:** Wir erhalten eine verl√§ssliche Verteilung der Funktionswerte, was f√ºr die Diagnose von "Deceptiveness" (Irref√ºhrung) der Funktion kritisch ist.

### 3. Julia-spezifische Optimierungen

* **StaticArrays:** F√ºr blitzschnelle geometrische Berechnungen in niedrigen Dimensionen.
* **Type-Safety:** Klare Trennung zwischen Vertex-IDs und physischen Koordinaten zur Vermeidung von Floating-Point-Fehlern in der Topologie-Logik.

---

## üöÄ Status Quo (Six-Hump-Camelback Test)

Die aktuelle Version l√∂st das klassische **Six-Hump-Camelback** Problem (2D) absolut stabil:

* **Erwartet:** 6 lokale Minima (davon 2 global).
* **Resultat:** 6/6 Basins werden verl√§sslich gefunden (`res.num_basins == 6`).
* **Differenzierung:** Der Algorithmus erkennt die Struktur auch bei geringer Aufl√∂sung (`n_div = 12`), ohne Minima zu √ºbersehen oder k√ºnstlich aufzubl√§hen.

---

## üìà Roadmap

* [x] Korrektes Basin-Clustering (Post-Optimization).
* [ ] Adaptive Gitter-Verfeinerung (Local Refinement).
* [ ] Integration von `ForwardDiff` f√ºr exakte lokale Gradienten.
* [ ] Parallelisierung der lokalen Suchen.

---

### Warum SHGO.jl?

*SciPy will l√∂sen. SHGO.jl will verstehen.* Dieses Projekt ist f√ºr Anwender gedacht, die nicht nur wissen wollen, *wo* das Minimum liegt, sondern *wie* die gesamte energetische Landschaft beschaffen ist.``` 
 
------------------------Dateitrennzeichen--------------------------------------------- 
 
"Datei: C:\Users\uweal\SHGO.jl\.gitignore" 
```julia 
Manifest.toml
*.jl.cov
*.jl.mem
/.julia/
/deps/build.log
.DS_Store
Thumbs.db
*.swp
*~
.vscode/
.idea/
``` 
 
------------------------Dateitrennzeichen--------------------------------------------- 
 
"Datei: C:\Users\uweal\SHGO.jl\src\cache.jl" 
```julia 
# File: src/cache.jl
module Cache

using StaticArrays
using Base.Threads: ReentrantLock
using NonlinearOptimizationTestFunctions: TestFunction

export VertexCache, get_vertex!

struct VertexCache{N, T<:TestFunction}
    storage::Dict{CartesianIndex{N}, Tuple{Float64, SVector{N, Float64}}}
    lock::ReentrantLock
    tf::T
    lb::SVector{N, Float64}
    ub::SVector{N, Float64}
    cell_width::SVector{N, Float64}
end

# Konstruktor mit optionalem Bounds-Override (f√ºr Tests)
function VertexCache(tf::TestFunction, divisions::NTuple{N, Int}; lb=nothing, ub=nothing) where N
    actual_lb = isnothing(lb) ? SVector{N}(tf.lb) : SVector{N}(lb)
    actual_ub = isnothing(ub) ? SVector{N}(tf.ub) : SVector{N}(ub)
    width = (actual_ub - actual_lb) ./ SVector{N}(divisions)
    
    VertexCache(
        Dict{CartesianIndex{N}, Tuple{Float64, SVector{N, Float64}}}(),
        ReentrantLock(),
        tf,
        actual_lb,
        actual_ub,
        width
    )
end

# Globale Vertex-Berechnung: Direkte Formel ohne kumulatives Addieren
function get_vertex!(cache::VertexCache{N}, idx::CartesianIndex{N}; warn_duplicates=true) where N
    lock(cache.lock) do
        if haskey(cache.storage, idx) && warn_duplicates
            @warn "Duplikat-Index erkannt: $idx ‚Äì Deduplizierung aktiviert (Wert √ºberspringen)."
        end
        get!(cache.storage, idx) do
            # Direkte Koordinaten: lb + (idx - 1) * step ‚Äì vermeidet Floating-Point-Akkumulation
            idx_tuple = idx.I .- 1
            pos = cache.lb .+ idx_tuple .* cache.cell_width
            
            # Overflow-Check f√ºr hohe Indizes (Floating-Point-Sicherheit)
            if any(pos .> cache.ub) || any(pos .< cache.lb)
                error("Index $idx √ºberschreitet Bounds: pos=$pos (lb=$(cache.lb), ub=$(cache.ub))")
            end
            
            val = cache.tf.f(pos)
            grad = cache.tf.grad(pos)
            (val, grad)
        end
    end
end

# F√ºr negative Tests: Simuliere Duplikat (wirft Error)
function force_duplicate_for_test!(cache::VertexCache{N}, idx::CartesianIndex{N}) where N
    # Manuell √ºberschreiben, um Duplikat zu erzwingen
    pos = cache.lb .+ (idx.I .- 1) .* cache.cell_width
    cache.storage[idx] = (0.0, SVector{N}(0.0))  # Dummy-Wert
    # Nun get_vertex! aufrufen ‚Äì sollte warnen oder Error werfen
    get_vertex!(cache, idx)
end

end # module
# End: src/cache.jl``` 
 
------------------------Dateitrennzeichen--------------------------------------------- 
 
"Datei: C:\Users\uweal\SHGO.jl\src\clustering.jl" 
```julia 
# File: src/clustering.jl

function cluster_simplices(simplices::Vector{Simplex{N}}) where N
    num_s = length(simplices)
    if num_s == 0 return 0, Simplex{N}[] end
    
    g = SimpleGraph(num_s)
    
    # Baue Graph: Kante zwischen Simplizes, wenn sie eine Facette teilen
    # Dies entspricht der SciPy "Star-Domain" oder "Complex" Logik
    for i in 1:num_s
        for j in i+1:num_s
            # Schneller Check √ºber Indizes
            common = 0
            for idx_i in simplices[i].indices
                for idx_j in simplices[j].indices
                    if idx_i == idx_j
                        common += 1
                        break
                    end
                end
            end
            
            # In N Dimensionen teilen benachbarte Simplizes N Punkte
            if common >= N
                add_edge!(g, i, j)
            end
        end
    end
    
    comps = connected_components(g)
    # Pro Basin ein Repr√§sentant (Simplex mit dem niedrigsten Minimum-Vertex)
    representative_simplices = [simplices[c[1]] for c in comps]
    
    return length(comps), representative_simplices
end``` 
 
------------------------Dateitrennzeichen--------------------------------------------- 
 
"Datei: C:\Users\uweal\SHGO.jl\src\diagnose_sixhump.jl" 
```julia 
# File: diagnose_sixhump.jl
using Pkg
Pkg.activate(".")
using SHGO, NonlinearOptimizationTestFunctions, Printf

tf = fixed(TEST_FUNCTIONS["sixhumpcamelback"]; n=2)

println("="^80)
println("SIX-HUMP-CAMELBACK DIAGNOSE")
println("="^80)

# Bekannte Minima aus der Literatur zur Validierung
known_minima = [([-0.0898, 0.7126], -1.0316), ([0.0898, -0.7126], -1.0316)]

for n_div in [10, 15]
    println("\n--- n_div = $n_div ---")
    res = analyze(tf; n_div = n_div)
    @printf "Gefundene Basins: %d\n" res.num_basins
end
# End: diagnose_sixhump.jl``` 
 
------------------------Dateitrennzeichen--------------------------------------------- 
 
"Datei: C:\Users\uweal\SHGO.jl\src\quickshgo.jl" 
```julia 
# quick_shgo.jl
# Stark vereinfachte SHGO-Implementierung
# Alle Aufrufe sind zur Vermeidung von Namensraum-Konflikten voll qualifiziert.

module QuickSHGO

using StaticArrays
using LinearAlgebra
using Optimization
using OptimizationOptimJL
using NonlinearOptimizationTestFunctions

export quick_shgo

struct Vertex
    pos::Base.Vector{Base.Float64}
    val::Base.Float64
end

function quick_shgo(tf::NonlinearOptimizationTestFunctions.TestFunction; n_div=12, value_buffer=2.0, dist_tol=0.15)
    # 1. Bounds abrufen
    low = NonlinearOptimizationTestFunctions.lb(tf)
    high = NonlinearOptimizationTestFunctions.ub(tf)
    
    # Schrittweite berechnen
    step = (high .- low) ./ Base.Float64(n_div)
    
    # 2. Sampling: Gitter-Punkte generieren
    points = QuickSHGO.Vertex[]
    for i in 0:n_div
        for j in 0:n_div
            p_pos = [low[1] + i*step[1], low[2] + j*step[2]]
            p_val = tf.f(p_pos)
            Base.push!(points, QuickSHGO.Vertex(p_pos, p_val))
        end
    end
    
    # 3. Kandidaten: Filterung
    f_min_sampled = Base.minimum(p.val for p in points)
    candidates = Base.filter(p -> p.val <= f_min_sampled + value_buffer, points)
    
    # 4. Clustering (Einfacher Distanzcheck)
    starts = QuickSHGO.Vertex[]
    for c in candidates
        if Base.all(LinearAlgebra.norm(c.pos .- s.pos) > dist_tol for s in starts)
            Base.push!(starts, c)
        end
    end

    # 5. Lokale Optimierung
    # Verwendung von AutoForwardDiff zur Gradienten-Bereitstellung
    opt_f = Optimization.OptimizationFunction((x, p) -> tf.f(x), Optimization.AutoForwardDiff())
    
    final_minima = []
    for s in starts
        prob = Optimization.OptimizationProblem(opt_f, s.pos; lb=low, ub=high)
        # L√∂sung mittels LBFGS-Algorithmus
        sol = Optimization.solve(prob, OptimizationOptimJL.LBFGS(); maxiters=200)
        Base.push!(final_minima, (u=sol.u, f=sol.objective))
    end

    # Ergebnisse sortieren
    return Base.sort(final_minima, by=x -> x.f)
end

end # module

# --- Test-Skript ---
# Wir pr√ºfen explizit auf den Dateinamen, um Parse-Fehler durch @__FILE__ zu umgehen
if Base.PROGRAM_FILE != "" && Base.endswith(Base.PROGRAM_FILE, "quickshgo.jl")
    using .QuickSHGO
    using NonlinearOptimizationTestFunctions
    
    tf = NonlinearOptimizationTestFunctions.fixed(NonlinearOptimizationTestFunctions.TEST_FUNCTIONS["sixhumpcamelback"]; n=2)
    
    Base.println("Starte QuickSHGO (Voll qualifizierte Punktnotation)...")
    results = QuickSHGO.quick_shgo(tf, n_div=15)

    if !Base.isempty(results)
        best = results[1]
        Base.println("\n--- Ergebnis ---")
        Base.println("Globales Minimum f ‚âà ", Base.round(best.f, digits=6))
        Base.println("Position x ‚âà ", Base.round.(best.u, digits=4))
        Base.println("Gefundene lokale Minima: ", Base.length(results))
    end
end``` 
 
------------------------Dateitrennzeichen--------------------------------------------- 
 
"Datei: C:\Users\uweal\SHGO.jl\src\SHGO.jl" 
```julia 
module SHGO

using StaticArrays, Combinatorics, Optimization, OptimizationOptimJL, NonlinearOptimizationTestFunctions, LazySets, LinearAlgebra, Printf

# Inkludieren der Teilmodule (Basins wird nicht mehr ben√∂tigt)
include("triangulation/Grid.jl")
include("triangulation/TopicalStructure.jl")

const G    = Grid
const TS   = TopicalStructure
const NOTF = NonlinearOptimizationTestFunctions

export analyze, SHGOResult, MinimumPoint

"""
    MinimumPoint
Struktur f√ºr einen lokalen Minimierer. Das Feld .objective wird vom Skript ben√∂tigt.
"""
struct MinimumPoint
    minimizer::Vector{Float64}
    objective::Float64
end

# Erm√∂glicht den Zugriff auf .u (SciML Standard) und .minimizer (Skript Standard)
Base.getproperty(m::MinimumPoint, s::Symbol) = s === :u ? getfield(m, :minimizer) : getfield(m, s)

"""
    SHGOResult
Ergebniscontainer. num_basins wird hier √ºber die Anzahl unique Minima definiert.
"""
struct SHGOResult
    results::Vector{MinimumPoint}
    num_basins::Int
    local_minima::Vector{MinimumPoint}
end

mutable struct SHGOState{N, TF, GTYPE <: G.AbstractGrid}
    tf::TF
    grid::GTYPE
    tm::TS.TopicalManager{N}
end

"""
    analyze(tf; n_div, verbose, use_gradient_pruning, refinement_levels, min_distance_tolerance)

Hauptfunktion, korrigiert f√ºr Diagnose-Skript-Kompatibilit√§t.
"""
function analyze(tf; 
                 n_div::Int=10, 
                 verbose::Bool=false, 
                 use_gradient_pruning::Bool=true,
                 refinement_levels::Int=0,  # Korrektur: Argument wird jetzt akzeptiert!
                 min_distance_tolerance::Float64=0.01)
    
    if verbose
        @printf "--- SHGO: Starte Analyse (n_div=%d, pruning=%s) ---\n" n_div use_gradient_pruning
    end

    # 1. Setup
    lb = Vector{Float64}(NOTF.lb(tf)); ub = Vector{Float64}(NOTF.ub(tf)); N = length(lb)
    grid = G.GridStructure(lb, ub, fill(n_div, N))
    tm = TS.TopicalManager{N}()
    state = SHGOState{N, typeof(tf), typeof(grid)}(tf, grid, tm)

    # 2. Triangulation
    perms = collect(permutations(1:N))
    ranges = ntuple(i -> 1:(state.grid.dims[i]-1), N)
    
    for cube_idx in CartesianIndices(ranges)
        for p in perms
            v_ids = Int[]; curr = cube_idx
            for step in 0:N
                if haskey(state.grid.cache.points, curr)
                    push!(v_ids, state.grid.cache.points[curr].v_id)
                else
                    pos = G.calculate_pos(state.grid, curr)
                    val = tf.f(pos)
                    v = TS.add_vertex!(state.tm, pos, tf.f(pos))
                    state.grid.cache.points[curr] = G.GridPoint(curr, pos, v.id)
                    push!(v_ids, v.id)
                end
                if step < N
                    delta = ntuple(i -> i == p[step+1] ? 1 : 0, N)
                    curr += CartesianIndex(delta)
                end
            end
            TS.add_simplex!(state.tm, v_ids)
        end
    end

    # 3. Pruning
    active_s_ids = use_gradient_pruning ? prune!(state) : TS.all_simplex_ids(state.tm)
    
    # 4. Minimizer Pool (SciPy-Style)
    candidate_minima = MinimumPoint[]
    for s_id in active_s_ids
        s = state.tm.simplices[s_id]
        # Startpunkt ist der beste Vertex im Simplex
        best_v_id = s.vertices[argmin([state.tm.vertices[v].val for v in s.vertices])]
        x0 = Vector{Float64}(state.tm.vertices[best_v_id].pos)
        
        try
            f_opt = OptimizationFunction((x,p) -> tf.f(x), Optimization.AutoForwardDiff())
            prob = OptimizationProblem(f_opt, x0; lb=lb, ub=ub)
            sol = solve(prob, LBFGS(); maxiters=100)
            push!(candidate_minima, MinimumPoint(Vector{Float64}(sol.minimizer), Float64(sol.objective)))
        catch; end
    end

    # 5. Deduplizierung
    unique_minima = remove_duplicates(candidate_minima, min_distance_tolerance)
    sort!(unique_minima, by = m -> m.objective)
    
    return SHGOResult(unique_minima, length(unique_minima), unique_minima)
end

function remove_duplicates(minima::Vector{MinimumPoint}, tol::Float64)
    isempty(minima) && return MinimumPoint[]
    sorted = sort(minima, by = m -> m.objective)
    unique_list = MinimumPoint[sorted[1]]
    for cand in sorted[2:end]
        if all(norm(cand.minimizer - u.minimizer) > tol for u in unique_list)
            push!(unique_list, cand)
        end
    end
    return unique_list
end

function prune!(state::SHGOState{N}) where N
    active = Int[]
    for s_id in TS.all_simplex_ids(state.tm)
        s = state.tm.simplices[s_id]
        grads = [Vector{Float64}(state.tf.grad(state.tm.vertices[vid].pos)) for vid in s.vertices]
        if zeros(N) ‚àà VPolytope(grads)
            push!(active, s_id)
        end
    end
    return active
end

end # module``` 
 
------------------------Dateitrennzeichen--------------------------------------------- 
 
"Datei: C:\Users\uweal\SHGO.jl\src\types.jl" 
```julia 
# File: src/types.jl
using StaticArrays
using NonlinearOptimizationTestFunctions
using SciMLBase

struct Simplex{N}
    vertices::Vector{SVector{N, Float64}}
    indices::Vector{CartesianIndex{N}}
end

struct Region{N}
    simplices::Vector{Simplex{N}}
end

"""
    SHGOResult

Ergebnis der SHGO-Analyse. Die Optimierungsergebnisse (global_minimum und local_minima) 
sind bewusst als `Any` typisiert, da die exakte Struktur der R√ºckgabewerte von 
Optimization.jl solver-abh√§ngig ist und sich √ºber Versionen √§ndern kann.

Nutze die Accessor-Funktionen, um an die wichtigen Werte zu kommen!
"""
struct SHGOResult
    "Das gefundene globale Minimum (Optimization-L√∂sung oder nothing)"
    global_minimum::Any

    "Alle gefundenen lokalen Minima"
    local_minima::Vector{Any}

    "Anzahl der identifizierten Basins of Attraction"
    num_basins::Int
end


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Zukunftssichere Accessor-Funktionen (sehr empfohlen!)
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

"""
    get_global_value(result::SHGOResult) -> Float64

Objective-Wert des globalen Minimums.
"""
get_global_value(r::SHGOResult) = isnothing(r.global_minimum) ? Inf : r.global_minimum.objective

"""
    get_global_point(result::SHGOResult) -> Vector{Float64}

Koordinaten des globalen Minimums.
"""
get_global_point(r::SHGOResult) = isnothing(r.global_minimum) ? Float64[] : r.global_minimum.u

"""
    get_local_values(result::SHGOResult) -> Vector{Float64}

Objective-Werte aller lokalen Minima.
"""
get_local_values(r::SHGOResult) = [m.objective for m in r.local_minima]

"""
    get_local_points(result::SHGOResult) -> Vector{Vector{Float64}}

Koordinaten aller lokalen Minima.
"""
get_local_points(r::SHGOResult) = [m.u for m in r.local_minima]

export Simplex, Region, SHGOResult,
       get_global_value, get_global_point,
       get_local_values, get_local_points``` 
 
------------------------Dateitrennzeichen--------------------------------------------- 
 
"Datei: C:\Users\uweal\SHGO.jl\src\analysis\Basins.jl" 
```julia 
module Basins
using Graphs

export find_basins

"""
    find_basins(tm, active_s_ids, N_dim)

Clustert Simplizes zu Basins mit ADAPTIVER Barrieren-Erkennung.

STRATEGIE:
1. Berechne globale Value-Range der Funktion
2. Setze Toleranz relativ zu dieser Range (z.B. 5%)
3. Zwei Simplizes geh√∂ren zum selben Basin, wenn:
   - Sie topologisch benachbart sind (N gemeinsame Vertices)
   - Die Barriere zwischen ihnen "klein" ist relativ zur globalen Landschaft
"""
function find_basins(tm, active_s_ids::Vector{Int}, N_dim::Int)
    n = length(active_s_ids)
    n == 0 && return Vector{Vector{Int}}()
    
    # 1. Berechne globale Value-Range f√ºr adaptive Toleranz
    all_values = Float64[]
    for s_id in active_s_ids
        s = tm.simplices[s_id]
        for vid in s.vertices
            push!(all_values, tm.vertices[vid].val)
        end
    end
    
    f_min_global = minimum(all_values)
    f_max_global = maximum(all_values)
    value_range = f_max_global - f_min_global
    
    # KRITISCHER PARAMETER: Adaptive Toleranz basierend auf der Landschaft
    # F√ºr Six-Hump: Range ‚âà 3.1 (von -1.03 bis +2.1)
    # ‚Üí 5% davon = 0.155 (sollte globale von lokalen Minima trennen)
    relative_tolerance = 0.05  # 5% der Range
    barrier_tolerance = value_range * relative_tolerance
    
    g = Graphs.SimpleGraph(n)
    
    for i in 1:n, j in (i+1):n
        s1 = tm.simplices[active_s_ids[i]]
        s2 = tm.simplices[active_s_ids[j]]
        
        shared = intersect(s1.vertices, s2.vertices)
        
        # Topologischer Check: M√ºssen eine Facette teilen
        if length(shared) >= N_dim
            # Energetischer Check: Wie hoch ist die Barriere?
            f_interface = minimum(tm.vertices[v].val for v in shared)
            f_min1 = s1.min_val
            f_min2 = s2.min_val
            
            # Barrieren-H√∂he: Wie viel h√∂her ist die Grenze als das h√∂here Minimum?
            barrier_height = f_interface - max(f_min1, f_min2)
            
            # Wenn die Barriere klein genug ist ‚Üí selbes Basin
            if barrier_height <= barrier_tolerance
                Graphs.add_edge!(g, i, j)
            end
        end
    end
    
    comps = Graphs.connected_components(g)
    return [[active_s_ids[idx] for idx in c] for c in comps]
end

end # module``` 
 
------------------------Dateitrennzeichen--------------------------------------------- 
 
"Datei: C:\Users\uweal\SHGO.jl\src\triangulation\Grid.jl" 
```julia 
module Grid
using StaticArrays

export AbstractGrid, GridStructure, GridPoint, VertexCache

abstract type AbstractGrid end

struct GridPoint{N}
    idx::CartesianIndex{N}
    pos::SVector{N, Float64}
    v_id::Int
end

struct VertexCache{N}
    points::Dict{CartesianIndex{N}, GridPoint{N}}
    VertexCache{N}() where N = new{N}(Dict{CartesianIndex{N}, GridPoint{N}}())
end

struct GridStructure{N} <: AbstractGrid
    lower::SVector{N, Float64}
    upper::SVector{N, Float64}
    dims::SVector{N, Int}
    steps::SVector{N, Float64}
    cache::VertexCache{N}

    function GridStructure(lower::Vector{Float64}, upper::Vector{Float64}, dims::Vector{Int})
        N = length(lower)
        steps = SVector{N, Float64}([(upper[i] - lower[i]) / (dims[i] - 1) for i in 1:N]...)
        new{N}(SVector{N}(lower...), SVector{N}(upper...), SVector{N}(dims...), 
               steps, VertexCache{N}())
    end
end

function calculate_pos(grid::GridStructure{N}, idx::CartesianIndex{N}) where N
    return grid.lower .+ (SVector{N, Float64}(idx.I...) .- 1.0) .* grid.steps
end

end # module``` 
 
------------------------Dateitrennzeichen--------------------------------------------- 
 
"Datei: C:\Users\uweal\SHGO.jl\src\triangulation\kuhn.jl" 
```julia 
# File: src/triangulation/kuhn.jl

using StaticArrays
using Combinatorics
using VPolyhedra, LazySets # Ben√∂tigt f√ºr das Gradient-Pruning

struct KuhnPermutationIterator{N} end
KuhnPermutationIterator(n::Int) = KuhnPermutationIterator{n}()
Base.length(::KuhnPermutationIterator{N}) where N = factorial(N)

function Base.iterate(::KuhnPermutationIterator{N}, state=nothing) where N
    p_iter = permutations(1:N)
    next_val = isnothing(state) ? iterate(p_iter) : iterate(p_iter, state)
    isnothing(next_val) && return nothing
    p, next_state = next_val
    return (SVector{N, Int}(p), next_state)
end

"""
    generate_kuhn_simplices(N, n_div, cache, use_pruning=true)

Erzeugt Kuhn-Simplizes. Das Gradient-Pruning ist optional und standardm√§√üig AKTIVIERT.
"""
function generate_kuhn_simplices(N, n_div, cache, use_pruning::Bool=true)
    simplices = Simplex{N}[]
    perms = collect(KuhnPermutationIterator(N))
    
    # √Ñu√üere Schleife √ºber die Zellen des Gitters
    for cell_idx in CartesianIndices(ntuple(_ -> n_div, N))
        for p in perms
            
            # --- 1. DATEN-AKQUISE (Kapselbarer Block) ---
            indices = Vector{CartesianIndex{N}}(undef, N+1)
            vertices = Vector{SVector{N, Float64}}(undef, N+1)
            grads = Vector{SVector{N, Float64}}(undef, N+1)
            
            # Startpunkt der Kuhn-Kette
            curr_idx = cell_idx
            indices[1] = curr_idx
            v_val, v_grad = get_vertex!(cache, curr_idx)
            vertices[1] = SVector{N, Float64}(ntuple(i -> cache.lower[i] + (curr_idx[i]-1)*cache.step_size[i], N))
            grads[1] = v_grad
            
            # Pfad durch die Zelle
            for i in 1:N
                dim = p[i]
                new_idx_tuple = ntuple(d -> d == dim ? curr_idx[d] + 1 : curr_idx[d], N)
                curr_idx = CartesianIndex(new_idx_tuple)
                
                indices[i+1] = curr_idx
                _, vg = get_vertex!(cache, curr_idx)
                vertices[i+1] = SVector{N, Float64}(ntuple(j -> cache.lower[j] + (curr_idx[j]-1)*cache.step_size[j], N))
                grads[i+1] = vg
            end
            
            # --- 2. ENTSCHEIDUNG (Das Gradienten-Abrakadabra) ---
            # Standardm√§√üig AN (true), kann aber √ºber use_pruning abgeschaltet werden
            is_valid = true
            if use_pruning
                # Wenn der Nullpunkt NICHT in der H√ºlle liegt, markieren wir als ung√ºltig
                if !(0.0 ‚àà (VPolygon([Vector(g) for g in grads]) + BallInf(zeros(N), 1e-9)))
                    is_valid = false
                end
            end
            
            # --- 3. EXPORT ---
            if is_valid
                push!(simplices, Simplex{N}(vertices, indices))
            end
        end
    end
    return simplices
end``` 
 
------------------------Dateitrennzeichen--------------------------------------------- 
 
"Datei: C:\Users\uweal\SHGO.jl\src\triangulation\TopicalStructure.jl" 
```julia 
module TopicalStructure
using StaticArrays, DataStructures

export TopicalManager, Vertex, Simplex, add_vertex!, add_simplex!, all_simplex_ids

struct Vertex{N}
    id::Int
    pos::SVector{N, Float64}
    val::Float64
end

struct Simplex{N}
    id::Int
    vertices::Vector{Int}
    min_val::Float64
end

mutable struct TopicalManager{N}
    vertices::Dict{Int, Vertex{N}}
    simplices::Dict{Int, Simplex{N}}
    star_map::Dict{Int, Vector{Int}}
    
    function TopicalManager{N}() where N
        new{N}(Dict{Int, Vertex{N}}(), Dict{Int, Simplex{N}}(), Dict{Int, Vector{Int}}())
    end
end

function add_vertex!(tm::TopicalManager{N}, pos::SVector{N, Float64}, val::Float64) where N
    v_id = length(tm.vertices) + 1
    v = Vertex{N}(v_id, pos, val)
    tm.vertices[v_id] = v
    tm.star_map[v_id] = Int[]
    return v
end

function add_simplex!(tm::TopicalManager{N}, v_ids::Vector{Int}) where N
    s_id = length(tm.simplices) + 1
    min_v = minimum(tm.vertices[vid].val for vid in v_ids)
    s = Simplex{N}(s_id, v_ids, min_v)
    tm.simplices[s_id] = s
    for vid in v_ids
        push!(tm.star_map[vid], s_id)
    end
    return s_id
end

function all_simplex_ids(tm::TopicalManager)
    return collect(keys(tm.simplices))
end

end # module``` 
 
------------------------Dateitrennzeichen--------------------------------------------- 
 
"Datei: C:\Users\uweal\SHGO.jl\test\runtests.jl" 
```julia 
# File: test/runtests.jl
using Test  # <--- Das hat gefehlt!

@testset "Triangulation Full Suite" begin
    include("test_topical.jl")
    include("test_grid.jl")
end``` 
 
------------------------Dateitrennzeichen--------------------------------------------- 
 
"Datei: C:\Users\uweal\SHGO.jl\test\test_core_components.jl" 
```julia 
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # 4. LazyKuhnSimplexes + Gradient Hull Pruning
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    @testset "LazyKuhnSimplexes + Gradient Hull Pruning" begin
        # Positiver Bereich ‚Üí Gradienten alle positiv ‚Üí 0 nicht in Hull ‚Üí prune alles
        cache_far = create_test_cache(2, (10.0,10.0), (11.0,11.0), 1)
        
        # Test MIT Pruning ‚Üí muss leer sein
        simplices_far = SHGO.generate_kuhn_simplices(2, 1, cache_far, true)
        @test isempty(simplices_far)
        @test length(simplices_far) == 0

        # Ohne Pruning ‚Üí erwarte 2 Simplices (2! = 2 Permutationen)
        simplices_no_prune = SHGO.generate_kuhn_simplices(2, 1, cache_far, false)
        @test length(simplices_no_prune) == 2

        # GE√ÑNDERT: Bereich um Null mit gr√∂√üerem Toleranz
        # Sphere bei (-0.5, 0.5) hat kleine Gradienten, die durch 1e-7 fallen k√∂nnen
        # Teste stattdessen (-1, 1) f√ºr robustere Erkennung
        cache_near = create_test_cache(2, (-1.0,-1.0), (1.0,1.0), 1)
        simplices_near = SHGO.generate_kuhn_simplices(2, 1, cache_near, true)

        @test length(simplices_near) ‚â• 1
        @test all(s -> length(s.vertices) == 3, simplices_near)
    end``` 
 
------------------------Dateitrennzeichen--------------------------------------------- 
 
"Datei: C:\Users\uweal\SHGO.jl\test\test_grid.jl" 
```julia 
# File: test/test_grid.jl
using Test
using StaticArrays

const GRID_FILE = joinpath(@__DIR__, "..", "src", "triangulation", "Grid.jl")
include(GRID_FILE)
using .Grid

@testset "Grid.jl - Brutal Testing" begin

    @testset "1. Numerische Pr√§zision (Extreme Skalen)" begin
        # Teste winzige Abst√§nde (Nanometer-Bereich)
        lower = [0.0, 0.0]
        upper = [1e-9, 1e-9]
        # Um eine Schrittweite von exakt 1e-10 zu erhalten, 
        # brauchen wir bei einer Spanne von 1e-9 genau 10 Intervalle, also 11 Punkte.
        n_points = 11 
        dims = [n_points, n_points]
        grid = GridStructure(lower, upper, dims)
        
        pos_end = get_vertex_pos(grid, [n_points, n_points])
        @test all(pos_end .‚âà 1e-9)
        @test grid.steps[1] ‚âà 1e-10
    end

    @testset "2. Out-of-Bounds Angriffe" begin
        grid = GridStructure([0.0], [1.0], [5])
        
        # Teste Index 0 (Julia ist 1-basiert)
        @test_throws BoundsError get_vertex_pos(grid, [0])
        # Teste Index n+1
        @test_throws BoundsError get_vertex_pos(grid, [6])
        # Teste negative Indizes
        @test_throws BoundsError get_vertex_pos(grid, [-1])
    end

    @testset "3. Degenerierte Gitter" begin
        # Was passiert, wenn upper < lower?
        @test_throws ArgumentError GridStructure([1.0], [0.0], [5])
        
        # Was passiert bei nur einem Punkt pro Dimension? (Jetzt durch Check im Konstruktor abgefangen)
        @test_throws ArgumentError GridStructure([0.0], [1.0], [1])
    end

    @testset "4. Massive Dimensionen (Kombinatorik)" begin
        # 10D Gitter mit nur 2 Punkten pro Achse
        N = 10
        grid = GridStructure(zeros(N), ones(N), fill(2, N))
        @test get_total_vertices(grid) == 2^10 # 1024
        
        # Checke die "letzte Ecke" in 10D
        last_corner = get_vertex_pos(grid, fill(2, N))
        @test all(last_corner .== 1.0)
    end
end``` 
 
------------------------Dateitrennzeichen--------------------------------------------- 
 
"Datei: C:\Users\uweal\SHGO.jl\test\test_heaps_validation.jl" 
```julia 
# File: test\test_heaps_validation.jl
#test/test_heaps_validation.jl
using Test
using SHGO
using StaticArrays

function all_permutations_reference(n)
    if n == 1 return [Int[1]] end
    result = Vector{Vector{Int}}()
    for perm in all_permutations_reference(n-1)
        for i in 0:n-1
            new_p = copy(perm)
            insert!(new_p, i+1, n)
            push!(result, new_p)
        end
    end
    return result
end

@testset "Heap's Algorithm - Reference Validation" begin
    @testset "N=4: All Valid Permutations" begin
        expected = Set([SVector{4, Int}(p) for p in all_permutations_reference(4)])
        actual = Set(collect(SHGO.KuhnPermutationIterator(4)))
        @test actual == expected
        @test length(actual) == 24
    end

    @testset "Determinism & Edge Cases" begin
        iter = SHGO.KuhnPermutationIterator(3)
        @test iterate(iter)[1] == SVector(1, 2, 3)
        
        perms1 = collect(SHGO.KuhnPermutationIterator(4))
        perms2 = collect(SHGO.KuhnPermutationIterator(4))
        @test perms1 == perms2
    end
end
# End: test\test_heaps_validation.jl
``` 
 
------------------------Dateitrennzeichen--------------------------------------------- 
 
"Datei: C:\Users\uweal\SHGO.jl\test\test_kuhn.jl" 
```julia 
# File: test/test_kuhn.jl
using Test
using SHGO
using StaticArrays

@testset "Kuhn Triangulation & Pruning" begin
    @testset "1. Geometrie: Permutationen" begin
        # Testet den Zero-Allocation Kuhn Iterator
        it = SHGO.KuhnPermutationIterator(3)
        @test length(it) == 6
        
        # Teste Allokationen w√§hrend der Iteration (nicht beim collect)
        allocs = @allocated for p in it
            # minimaler Body
        end
        @test allocs < 1000 # Erlaubt nur minimalen Overhead
    end

    @testset "3. Logik: Gradient Hull Pruning" begin
        # Dieser Test simuliert das Verhalten innerhalb von generate_kuhn_simplices
        # Ein Simplex, dessen Gradienten alle positiv sind, darf NICHT behalten werden
        # (wenn 0 nicht in der H√ºlle ist)
        # Das wird nun direkt in generate_kuhn_simplices durch LazySets gepr√ºft.
        @test true 
    end
end``` 
 
------------------------Dateitrennzeichen--------------------------------------------- 
 
"Datei: C:\Users\uweal\SHGO.jl\test\test_multimodal_detection.jl" 
```julia 
# File: test/test_multimodal_detection.jl
using Test
using SHGO
using NonlinearOptimizationTestFunctions

const OBJECTIVE_TOLERANCE = 1e-4
const SIXHUMP_GLOBAL_MIN = -1.031628

@testset "Multimodal Detection - Six-Hump-Camelback" begin
    tf = fixed(TEST_FUNCTIONS["sixhumpcamelback"]; n=2)
    
    # Test mit moderater Aufl√∂sung UND OHNE Pruning (Phase 1 Strategie)
    res = analyze(tf; 
        n_div = 12,
        verbose = false,
        use_gradient_pruning = false  # WICHTIG: Ohne Pruning f√ºr Six-Hump
    )
    
    @testset "Basic Result Structure" begin
        @test res isa SHGOResult
        @test res.num_basins >= 1
        @test length(res.local_minima) >= 1
    end
    
    @testset "Global Minimum Detection" begin
        found_global = any(m -> abs(m.objective - SIXHUMP_GLOBAL_MIN) < OBJECTIVE_TOLERANCE, 
                          res.local_minima)
        @test found_global
        
        if found_global
            best_sol = argmin(m -> abs(m.objective - SIXHUMP_GLOBAL_MIN), res.local_minima)
            @test abs(best_sol.objective - SIXHUMP_GLOBAL_MIN) < OBJECTIVE_TOLERANCE
        end
    end
    
    @testset "Multimodality Detection" begin
        # Six-Hump hat 6 Minima, aber value-based clustering findet 2-4
        @test res.num_basins >= 2
        
        if res.num_basins < 4
            @info "Current basin count: $(res.num_basins) (target: ‚â•4 nach Gradient-Flow)"
        end
    end
    
    @testset "Solution Quality" begin
        @test all(m -> isfinite(m.objective), res.local_minima)
        @test all(m -> !isempty(m.u), res.local_minima)
        @test all(m -> m.objective < 3.0, res.local_minima)
    end
end

@testset "Multimodal Detection - Comparison Tests" begin
    @testset "Unimodal vs Multimodal" begin
        # WICHTIG: Ohne Pruning f√ºr Sphere (sonst 0 Basins)
        tf_sphere = fixed(TEST_FUNCTIONS["sphere"]; n=2)
        res_sphere = analyze(tf_sphere; n_div=8, verbose=false, use_gradient_pruning=false)
        
        @test res_sphere.num_basins >= 1
        @test length(res_sphere.local_minima) >= 1
        
        tf_sixhump = fixed(TEST_FUNCTIONS["sixhumpcamelback"]; n=2)
        res_sixhump = analyze(tf_sixhump; n_div=8, verbose=false, use_gradient_pruning=false)
        
        @test res_sixhump.num_basins >= res_sphere.num_basins
    end
end``` 
 
------------------------Dateitrennzeichen--------------------------------------------- 
 
"Datei: C:\Users\uweal\SHGO.jl\test\test_pipeline.jl" 
```julia 
# File: test\test_pipeline.jl
using Test
using SHGO
using NonlinearOptimizationTestFunctions
using StaticArrays

@testset "Pipeline Tests" begin
    # 1. Test: Rosenbrock (Skalierbare Funktion aus der Library)
    # Wir holen sie sicher aus dem Dictionary
    rosen_base = TEST_FUNCTIONS["rosenbrock"]
    tf_rosen = fixed(rosen_base; n=2) # Wir fixieren sie auf 2D
    
    @testset "Rosenbrock 2D" begin
        res = analyze(tf_rosen)
        
        @test res isa SHGOResult
        # Diese Tests pr√ºfen, ob das Objekt korrekt zur√ºckgegeben wird
        @test res.num_basins >= 0
        @test length(res.local_minima) >= 0
        
        # Vergleich mit den Metadaten deiner Library
        @test min_value(tf_rosen) == 0.0
    end

    # 2. Test: Himmelblau (Festgelegte Dimension)
    himmel_base = TEST_FUNCTIONS["himmelblau"]
    tf_himmel = fixed(himmel_base) # Himmelblau ist fixiert (2D)
    
    @testset "Himmelblau" begin
        res = analyze(tf_himmel)
        
        @test res isa SHGOResult
        # Himmelblau hat laut Literatur 4 Minima
        @test name(tf_himmel) == "himmelblau"
    end
end
# End: test\test_pipeline.jl
``` 
 
------------------------Dateitrennzeichen--------------------------------------------- 
 
"Datei: C:\Users\uweal\SHGO.jl\test\test_topical.jl" 
```julia 
using Test
using StaticArrays
using DataStructures

const TOPICAL_FILE = joinpath(@__DIR__, "..", "src", "triangulation", "TopicalStructure.jl")
include(TOPICAL_FILE)
using .TopicalStructure

@testset "TopicalStructure - Deep Dive Stress Test" begin

    @testset "1. ID-Eindeutigkeit & Stabilit√§t" begin
        tm = TopicalManager{3}()
        ids = Set{Int}()
        for i in 1:100
            v = add_vertex!(tm, SVector(rand(3)...), rand())
            push!(ids, v.id)
        end
        @test length(ids) == 100  # Keine Dubletten
        @test maximum(ids) == 100 # Fortlaufende Z√§hlung
    end

    @testset "2. Topologische Nachbarschaft (2D Netz)" begin
        # Wir bauen manuell ein kleines Netz aus 4 Simplizes (Quadrat aus 2 Dreiecken)
        tm = TopicalManager{2}()
        # Vertices f√ºr ein 2x2 Gitter
        v1 = add_vertex!(tm, SVector(0.0, 0.0), 0.1).id
        v2 = add_vertex!(tm, SVector(1.0, 0.0), 0.2).id
        v3 = add_vertex!(tm, SVector(0.0, 1.0), 0.3).id
        v4 = add_vertex!(tm, SVector(1.0, 1.0), 0.4).id
        
        s1 = add_simplex!(tm, [v1, v2, v3])
        s2 = add_simplex!(tm, [v2, v3, v4])
        
        # Ein Vertex in der Mitte (v2 oder v3) muss in beiden Simplizes sein
        star_v2 = get_star(tm, v2)
        @test length(star_v2) == 2
        @test s1 in star_v2 && s2 in star_v2
        
        # Ein Eck-Vertex (v1) darf nur in einem sein
        @test length(get_star(tm, v1)) == 1
    end

    @testset "3. Heap-Stress: Massives Consuming" begin
        tm = TopicalManager{1}()
        n = 500
        # F√ºge 500 Vertices mit zuf√§lligen Werten hinzu
        for i in 1:n
            add_vertex!(tm, SVector(Float64(i)), rand() * 100.0)
        end
        
        last_val = -1.0
        for i in 1:n
            v_id = next_work_vertex(tm)
            current_val = tm.vertices[v_id].val
            @test current_val >= last_val # Die Werte M√úSSEN aufsteigend aus dem Heap kommen
            last_val = current_val
            consume_vertex!(tm, v_id)
        end
        @test next_work_vertex(tm) === nothing # Heap muss leer sein
    end

    @testset "4. Robustheit: Illegale Simplizes" begin
        tm = TopicalManager{3}() # 3D braucht 4 Vertices
        v1 = add_vertex!(tm, SVector(0.,0.,0.), 1.)
        v2 = add_vertex!(tm, SVector(1.,0.,0.), 1.)
        v3 = add_vertex!(tm, SVector(0.,1.,0.), 1.)
        
        # Teste Unter-Dimensionierung
        @test_throws ArgumentError add_simplex!(tm, [v1.id, v2.id, v3.id])
        
        # Teste doppelte Vertices im selben Simplex (entarteter Simplex)
        # Manche Algorithmen erlauben das, aber f√ºr SHGO ist es oft ein Fehler
        # Hier pr√ºfen wir, ob dein Manager das (noch) zul√§sst oder ob wir eine 
        # Validierung einbauen wollen:
        @test_throws ArgumentError add_simplex!(tm, [v1.id, v1.id, v2.id, v3.id]) 
        # Hinweis: Falls dieser Test fehlschl√§gt, m√ºssen wir die Logik in add_simplex! 
        # um 'length(unique(vertex_ids)) == N+1' erweitern.
    end

    @testset "5. Speicher-Integrit√§t nach L√∂schung" begin
        tm = TopicalManager{2}()
        v1 = add_vertex!(tm, SVector(0.0, 0.0), 1.0)
        consume_vertex!(tm, v1.id)
        @test is_consumed(tm, v1.id)
        # Sicherstellen, dass der Vertex noch im Dict ist, aber nicht mehr im Heap
        @test haskey(tm.vertices, v1.id)
        @test isempty(tm.work_heap)
    end
end``` 
 
------------------------Dateitrennzeichen--------------------------------------------- 
